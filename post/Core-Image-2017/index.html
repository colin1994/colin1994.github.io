<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Core Image【3】—— 2017 新特性 | Menco&#39;s Space</title>
<link rel="shortcut icon" href="https://colin1994.github.io/favicon.ico?v=1689393277588">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://colin1994.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Core Image【3】—— 2017 新特性 | Menco&#39;s Space - Atom Feed" href="https://colin1994.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="Core Image 系列，目前的文章如下：

Core Image 你需要了解的那些事~
Core Image 之自定义 Filter~
Core Image【3】—— 2017 新特性
Core Image【4】—— 2018 新特性
..." />
    <meta name="keywords" content="Core Image,图像处理,iOS" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://colin1994.github.io">
  <img class="avatar" src="https://colin1994.github.io/images/avatar.png?v=1689393277588" alt="">
  </a>
  <h1 class="site-title">
    Menco&#39;s Space
  </h1>
  <p class="site-description">
    花开如火，也如寂寞
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/colin1994" target="_blank">
          <i class="ri-github-line"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Core Image【3】—— 2017 新特性
            </h2>
            <div class="post-info">
              <span>
                2017-10-27
              </span>
              <span>
                16 min read
              </span>
              
                <a href="https://colin1994.github.io/tag/R5xqGhbOH/" class="post-tag">
                  # Core Image
                </a>
              
                <a href="https://colin1994.github.io/tag/H8Abw3S15m/" class="post-tag">
                  # 图像处理
                </a>
              
                <a href="https://colin1994.github.io/tag/MzdMzxo8o/" class="post-tag">
                  # iOS
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305242318102.webp" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <p>Core Image 系列，目前的文章如下：</p>
<ul>
<li><a href="https://colin1994.github.io/post/Core-Image-OverView/">Core Image 你需要了解的那些事~</a></li>
<li><a href="https://colin1994.github.io/post/Core-Image-Custom-Filter/">Core Image 之自定义 Filter~</a></li>
<li><a href="https://colin1994.github.io/post/Core-Image-2017/">Core Image【3】—— 2017 新特性</a></li>
<li><a href="https://colin1994.github.io/post/Core-Image-2018/">Core Image【4】—— 2018 新特性</a></li>
</ul>
<blockquote>
<p>如果想了解 Core Image 相关，建议按序阅读，前后有依赖。</p>
<p>对应源码，见最末链接。</p>
</blockquote>
<hr>
<h2 id="概述">概述</h2>
<p>先回顾一下 Core Image 目前强大的功能。</p>
<ul>
<li>A simple, high-performance API to apply filters to images，提供简单使用，性能优秀的 API，以及内置各种 CIFiter，方便处理图片</li>
<li>Automatically tiles if images are large or graph is complex，大图处理优化</li>
<li>Automatically tiles if only a region of the output is rendered，只处理部分区域</li>
<li>Each CIFilter has one or more CIKernel functions，自定义 CIFliter</li>
<li>Multiple CIKernels are concatenated to improve performance，滤镜链延迟处理，合并成一个</li>
</ul>
<p>这几点之前的文章都详细描述过了，这里不再说明。</p>
<p>2017 年，额外引入了一些新的东西，具体如下：</p>
<figure data-type="image" tabindex="1"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211058783.png" alt="" loading="lazy"></figure>
<p>从三个方面讨论，<strong>性能，调试信息，新功能。</strong></p>
<p><strong>性能：</strong></p>
<ul>
<li>支持使用 <strong>Metal</strong> 直接自定义 CIKernel，提高效率</li>
<li>引入 <strong>CIRenderDestination</strong>，更方便，性能更好的渲染到指定目的地</li>
</ul>
<p><strong>信息：</strong></p>
<ul>
<li><strong>CIRenderInfo</strong>，包含更多的信息</li>
<li><strong>Quick Looks</strong>，支持 Core Image 多个对象直观调试</li>
</ul>
<p><strong>新功能：</strong></p>
<ul>
<li>更多内置滤镜</li>
<li>条码扫描支持</li>
<li>与不同框架的协同处理</li>
</ul>
<p>下面逐一展开说明。</p>
<h2 id="性能">性能</h2>
<h3 id="metal">Metal</h3>
<p>先回顾旧的 CIKernel 编写方式，之前的文章也提到过，Core Image 支持自定义 CIFilter，它们的脚本是通过  CIKernel Language 编写的， CIKernel Language 又基于 GLSL。</p>
<p>所以，当我们运行 App 时候，要用到这个 Filter，那么<strong>系统会自动帮我们把对应的 kernel，翻译成 GLSL 或者 Metal 规范的 kernel。然后再编译得到的 kernel。</strong></p>
<p>所以之前的方式，存在两个问题：</p>
<ul>
<li>编写 kernel 的时候，没有报错提示，哪怕是参数名错误都无法检查处理。效率极低。</li>
<li>翻译转换，编译，都是发生到运行时，导致第一次使用滤镜的时候，耗时较久。</li>
</ul>
<p>关于耗时这点，具体如下：</p>
<figure data-type="image" tabindex="2"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211058299.png" alt="" loading="lazy"></figure>
<p>这里的各个阶段分别指：</p>
<ul>
<li>Translate CIKernels，转换 kernel，转成其他格式的。</li>
<li>Concatenate CIKernels，按序连接 kernel，滤镜链里头提到过</li>
<li>Compile CIKernels to Intermediate Representation，编译 CIKernel，这里的 IR（中间代码）我们无需关心，也干预不到</li>
<li>Compile to GPU Code，将 IR 转成 GPU 识别的代码</li>
<li>Render，在 GPU 上渲染</li>
</ul>
<p>在旧的模式里面，这五步都是<strong>发生在运行时，且无法避免。</strong></p>
<p>CIKernel 编译后会有缓存机制，所以耗时<strong>第一次</strong>较为明显。</p>
<p>这就导致了一个问题，你可能只需要渲染一次，显示带效果的图片。但是哪怕你的图片很小，也需要相当久的等待，因为需要对 CIKernel 进行转换编译。</p>
<p>进一步拆分，必须发生在运行时的，包含 Concatenate CIKernels，Compile to GPU Code 以及 Render，因为拼接滤镜可能是动态的，没法一开始就确定下来。</p>
<figure data-type="image" tabindex="3"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211058693.png" alt="" loading="lazy"></figure>
<p>而占大头的前两部，并不是一定需要在运行时才能处理的。Metal 恰恰能解决。</p>
<p><strong>将 Kernel 的编译时间，提前到 App 编译阶段，并且有语法错误检查，大大提高效率。</strong></p>
<figure data-type="image" tabindex="4"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211058793.png" alt="" loading="lazy"></figure>
<p>那么，具体怎么用 Metal 编写 CIKernel 呢，对比旧的流程，有什么差异呢？下面举个实际例子。将上一篇文章里面实现的 Vignette， 改用 Metal 处理，便于参照。</p>
<h4 id="write-cikernel-in-metal-shader-file">Write CIKernel in Metal shader file</h4>
<p>CIKL（CIKernel Language） 和 Metal 本质上是很相似的，基础语法都是一样的。</p>
<blockquote>
<p>关于语法类的东西，这里不细说，具体可以参照官方说明来。<a href="https://developer.apple.com/metal/MetalCIKLReference6.pdf">MetalCIKLReference</a></p>
</blockquote>
<p>这里提一点。CIKL 之前为了特性，扩展的那些支持， Metal 也同样支持。具体的转换规则如下：</p>
<figure data-type="image" tabindex="5"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211059014.png" alt="" loading="lazy"></figure>
<p>所以不同类型的 CIKernel，它们的简单转换应该是这样：</p>
<p><strong>CIWarpKernel</strong>：</p>
<figure data-type="image" tabindex="6"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211059216.png" alt="" loading="lazy"></figure>
<p><strong>CIColorKernel</strong>：</p>
<figure data-type="image" tabindex="7"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211059946.png" alt="" loading="lazy"></figure>
<p><strong>CIKernel</strong>:<br>
<img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211059828.png" alt="" loading="lazy"></p>
<p>基本上，差异都体现在额外扩展的这些内容。实际的算法编写，基本不变。</p>
<p>我们以之前实现的 <strong>vignetteKernel</strong> 为例，<strong>Vignette.cikernel</strong> 白板代码如下：</p>
<pre><code>kernel vec4 vignetteKernel(__sample image, vec2 center, float radius, float alpha)
{
	// 计算出当前点与中心的距离
	float distance = distance(destCoord(), center) ;
	// 根据距离计算出暗淡程度
	float darken = 1.0 - (distance / radius * alpha);
	// 返回该像素点最终的色值
	image.rgb *= darken;
	return image.rgba;
}
</code></pre>
<p>转换成 <strong>Metal</strong> 应该是：<strong>Vignette.metal</strong> ：</p>
<pre><code class="language-c++">#include &lt;metal_stdlib&gt;
using namespace metal;

#include &lt;CoreImage/CoreImage.h&gt; // includes CIKernelMetalLib.h

extern &quot;C&quot; { namespace coreimage {
    float4 vignetteMetal(sample_t image, float2 center, float radius, float alpha, destination dest) {
        // 计算出当前点与中心的距离
        float distance2 = distance(dest.coord(), center);
        
        // 根据距离计算出暗淡程度
        float darken = 1.0 - (distance2 / radius * alpha);
        // 返回该像素点最终的色值
        image.rgb *= darken;
        
        return image.rgba;
    }
}}
</code></pre>
<p>这里有几个改变点逐一说下：</p>
<pre><code class="language-c++">#include &lt;metal_stdlib&gt;
using namespace metal;

#include &lt;CoreImage/CoreImage.h&gt; // includes CIKernelMetalLib.h

extern &quot;C&quot; { namespace coreimage {
}}
</code></pre>
<p>这里需要引入对应的库，以及命名空间。因为系统内部的实现大致是这样的：</p>
<figure data-type="image" tabindex="8"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211059336.png" alt="" loading="lazy"></figure>
<p>这基本是固定的格式，保持就好。</p>
<p>然后就是特定的修改：</p>
<ul>
<li>__sample —&gt; sample_t</li>
<li>vec2 — &gt; float2</li>
<li>destCoord() —&gt; dest.coord()</li>
<li>vec4 —&gt; float4</li>
</ul>
<p>这里注意，Metal 不支持 vec 类型，参数类型都需要转成浮点值类型。</p>
<p>另外，入参这里，多了一个 <strong>destination dest</strong>，这个对应 CIColorKernel 是可选的，因为并不一定要获取当前的坐标，正常像素值就够了。</p>
<p>如果要带的话，<strong>它是隐式的，必须放在参数列表最后一个</strong>，无须我们传参，系统自动赋值。这点需要额外注意！</p>
<p>至此，shader 的编写就结束了，也是很好理解。</p>
<h4 id="compile-and-link-metal-shader-file">Compile and link Metal shader file</h4>
<p>至于编译，Xcode 默认是不会帮我们编译 CIKernel 对应的 Metal 文件，需要我们显示的去设置。</p>
<p>具体步骤如下：</p>
<p>Build Settings 里头找到 <strong>Other Metal Compiler Flags</strong>，添加值：<strong>-fcikernel</strong></p>
<figure data-type="image" tabindex="9"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211100633.png" alt="" loading="lazy"></figure>
<p>然后新增一个自定义配置</p>
<figure data-type="image" tabindex="10"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211100078.png" alt="" loading="lazy"></figure>
<p>对应的 Key 为： <strong>MTLLINKER_FLAGS</strong>，value 为：<strong>-cikernel</strong></p>
<figure data-type="image" tabindex="11"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211100419.png" alt="" loading="lazy"></figure>
<blockquote>
<p>PS：</p>
<p>如果没添加对应的编译选项，下一步初始化 CIKernel 的时候，会失败。</p>
</blockquote>
<h4 id="initialize-cikernel">Initialize CIKernel</h4>
<p>这里同样对比旧的创建方式，</p>
<pre><code class="language-objc">NSBundle *bundle = [NSBundle bundleForClass: [self class]];
NSURL *kernelURL = [bundle URLForResource:@&quot;Vignette&quot; withExtension:@&quot;cikernel&quot;];

NSError *error;
NSString *kernelCode = [NSString stringWithContentsOfURL:kernelURL
                                                encoding:NSUTF8StringEncoding
                                                   error:&amp;error];
NSArray *kernels = [CIColorKernel kernelsWithString:kernelCode];
customKernel = [kernels objectAtIndex:0];
</code></pre>
<p>只需要改为：</p>
<pre><code class="language-objc">NSURL *kernelURL = [[NSBundle mainBundle] URLForResource:@&quot;default&quot; withExtension:@&quot;metallib&quot;];
NSError *error;
NSData *data = [NSData dataWithContentsOfURL:kernelURL];
customKernel = [CIColorKernel kernelWithFunctionName:@&quot;vignetteMetal&quot;
                                fromMetalLibraryData:data
                                               error:&amp;error];
</code></pre>
<p>初始化方法不一样，在使用上是一致的。</p>
<p>至此，通过 Metal 自定义 CIFilter 的流程，已经全部走通了。对旧有的修改很小。<br>
这里额外提一点，UIImageView 针对 CIImage 有做优化，如果一个 UIImage 是通过 UIImage.init(ciImage:) 这种方式创建的，</p>
<p><strong>设置到 UIImageView 上的时候，UIImageView 会在 GPU 上执行 Core Image 相关操作。GPU 处理很高效，并且能释放 CPU 压力。</strong></p>
<p>所以，实时调整 Filter 的时候，也可以借助 UIImageView 来直接显示，效率很高：</p>
<pre><code class="language-objc">@interface MetalKernelViewController ()

@property (strong, nonatomic) MetalKernelFilter *vignetteFilter;
@property (strong, nonatomic) CIImage *inputImage;
@property (strong, nonatomic) IBOutlet UIImageView *imageView;

@end

@implementation MetalKernelViewController

- (void)viewDidLoad {
    [super viewDidLoad];
    // Do any additional setup after loading the view.
    
    // 初始化 Filter
    self.vignetteFilter = [[MetalKernelFilter alloc] init];
    NSURL *imageURL = [[NSBundle mainBundle] URLForResource:@&quot;vignetteImage&quot; withExtension:@&quot;jpg&quot;];
    self.inputImage = [CIImage imageWithContentsOfURL:imageURL];
    [self.vignetteFilter setValue:_inputImage forKey:@&quot;inputImage&quot;];
    
    self.imageView.image = [UIImage imageWithCIImage:self.inputImage];
    
}

#pragma mark - Action
- (IBAction)alphaChanged:(UISlider *)sender {
    [self.vignetteFilter setValue:@(sender.value) forKey:@&quot;inputAlpha&quot;];
    CIImage *result = _vignetteFilter.outputImage;
    self.imageView.image = [UIImage imageWithCIImage:result];
}

@end
</code></pre>
<h3 id="cirenderdestination">CIRenderDestination</h3>
<p>这是一个新增的 API，iOS 11 之后支持，方便渲染到指定的目的地。</p>
<p>目前支持：</p>
<ul>
<li>IOSurface</li>
<li>CVPixelBuffer</li>
<li>Metal Texture</li>
<li>OpenGL Texture</li>
<li>Memory buffer</li>
</ul>
<p>基本涵盖了所有我们需要用来显示的对象。</p>
<p>比如：</p>
<pre><code class="language-objc">- (instancetype) initWithMTLTexture:(id&lt;MTLTexture&gt;)texture
                      commandBuffer:(nullable id&lt;MTLCommandBuffer&gt;)commandBuffer;
</code></pre>
<p>当我们需要执行渲染的时候，就可以使用：</p>
<pre><code class="language-objc">- (nullable CIRenderTask*) startTaskToRender:(CIImage*)image
                               toDestination:(CIRenderDestination*)destination
                                       error:(NSError**)error NS_AVAILABLE(10_13, 11_0);
</code></pre>
<p>当然，你可能有发现，旧的 API 也是支持渲染到指定目的地的，比如：</p>
<pre><code class="language-objc">- (void)render:(CIImage *)image 
toCVPixelBuffer:(CVPixelBufferRef)buffer NS_AVAILABLE(10_11,5_0);
</code></pre>
<p>那么，新的 API 有什么优势呢？我具体罗列了以下几点：</p>
<ul>
<li>如果渲染失败，会立即返回错误信息，便于排查问题，旧的是不支持。</li>
<li>另外，渲染时，可以额外指定结果的一些属性，比如是否翻转，颜色空间，alpha 混合模式等。不需要额外的操作，性能高。</li>
<li>另外，支持这些属性后，不需要额外创建多个 CIContext。之前处理的话，有的属性和具体的 CIContext 关联，导致配置不同参数的时候，需要依赖多个。现在只要一个就可以了。</li>
<li>性能更好，速度快。旧的 API，需要等到所有提交到 GPU 的渲染命令，执行完毕后，才执行新的渲染操作。新的 API，当 CPU 提交完所有命令到 GPU 后，就可以开始执行新的，不需要等到 GPU 处理完。CPU 和 GPU 之间的协同工作更加高效。</li>
</ul>
<blockquote>
<p>They used to return after all the render on the GPU is completed.</p>
<p>But now with this new API, it will return as soon as the CPU has finished issuing all the work for the GPU.</p>
<p>And without having to wait for the GPU work to finish.</p>
<p>So we think this new flexibility will now allow you to pipeline all your CPU and GPU work much more efficiently.</p>
</blockquote>
<p>额外支持的属性：</p>
<pre><code class="language-objc">@property CIRenderDestinationAlphaMode alphaMode;
@property (getter=isFlipped) BOOL flipped;
@property (getter=isDithered) BOOL dithered;
@property (getter=isClamped) BOOL clamped;
@property (nullable, nonatomic) CGColorSpaceRef colorSpace;
@property (nullable, nonatomic, retain) CIBlendKernel* blendKernel;
@property BOOL blendsInDestinationColorSpace;
</code></pre>
<h2 id="调试信息">调试信息</h2>
<p>这里主要包含两点：</p>
<ul>
<li>CIRenderInfo</li>
<li>Quick Look</li>
</ul>
<h3 id="cirenderinfo">CIRenderInfo</h3>
<p>CIRenderInfo 是新增的对象，它里面包含了一些有用的信息，比如 kernel 执行耗时，当前有多少数量的像素参与处理等。</p>
<pre><code class="language-objc">// An Xcode quicklook of this object will show a graph visualization of the render
// with detailed timing information.
NS_CLASS_AVAILABLE(10_13, 11_0)
@interface CIRenderInfo : NSObject
{
    void *_priv;
}

// This property will return how much time a render spent executing kernels.
@property (readonly) NSTimeInterval kernelExecutionTime;

// This property will return how many passes the render requires.
// If passCount is 1 than the render can be fully concatinated and no
// intermediate buffers will be required.
@property (readonly) NSInteger passCount;

// This property will return how many pixels a render produced executing kernels.
@property (readonly) NSInteger pixelsProcessed;

@end
</code></pre>
<h3 id="quick-look">Quick Look</h3>
<p>Core Image 对很对对象新增了 Quick Look 支持，方便调试查看效果。</p>
<p>关于调试信息这点，前两篇文章其实有提到其他方式，只是都没有 Quick Look 来得方便。</p>
<figure data-type="image" tabindex="12"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211100398.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="13"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211100270.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="14"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211101579.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="15"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211101124.png" alt="" loading="lazy"></figure>
<p>图表都支持放大查阅，具体的大家可以实际查阅。信息还是很有用的，包含多个滤镜是怎么组合的等等细节。</p>
<h2 id="新功能">新功能</h2>
<h3 id="new-filter">New Filter</h3>
<p>现在内置了 196 个 filters</p>
<figure data-type="image" tabindex="16"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211101722.png" alt="" loading="lazy"></figure>
<p>内置的滤镜，有新增，也有性能优化。这里不展开讲。</p>
<p>一般都是用到的时候，去查找是否有合适的内置滤镜，而不是一开始就把这近 200 个滤镜都掌握下来。</p>
<p>具体的可以查阅： <a href="https://developer.apple.com/library/archive/documentation/GraphicsImaging/Reference/CoreImageFilterReference/index.html#//apple_ref/doc/uid/TP40004346">Core Image Filter Reference</a></p>
<h3 id="cibarcodedescriptor">CIBarcodeDescriptor</h3>
<p>App 现在支持各种各样的条码扫描，识别。</p>
<figure data-type="image" tabindex="17"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211101235.png" alt="" loading="lazy"></figure>
<p>并且，各个不同的框架，通过新引入的 CIBarcodeDescriptor，能够协调工作。</p>
<figure data-type="image" tabindex="18"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211101183.png" alt="" loading="lazy"></figure>
<p>这里，可以通过 AVFoundation 框架，实时获取图像，并检测识别得到 CIBarcodeDescriptor 对象。</p>
<pre><code class="language-swift">// Get a CIBarcodeDescriptor from AVFoundation.framework
class MyMetadataOutputObjectsDelegate: NSObject, AVCaptureMetadataOutputObjectsDelegate
{
    func metadataOutput(_ output: AVCaptureMetadataOutput,
                        didOutput metadataObjects: [AVMetadataObject],
                        from connection: AVCaptureConnection) {
        if let mrc = metadataObjects.first as? AVMetadataMachineReadableCodeObject,
          let descriptor = mrc.descriptor {
              print(descriptor)
        }
    }
}
</code></pre>
<p>当然，对于静态图片，或者录制好的视频文件，也可以通过 Vision 框架检测识别得到 CIBarcodeDescriptor 对象。</p>
<pre><code class="language-swift">// Detect a CIBarcodeDescriptor using Vision.framework
func descriptorFromImage(_ image: CIImage) -&gt; CIBarcodeDescriptor?
{
    // Create the request and request handler
    let requestHandler = VNImageRequestHandler(ciImage: image, options: [:])
    let request = VNDetectBarcodesRequest();

    // Send the request to the handler
    try? requestHandler.perform([request])

    // Get the observation
    let firstResult = request.results?.first 
    return firstResult?.barcodeDescriptor
}
</code></pre>
<p>而获取到的 CIBarcodeDescriptor，则可以通过 Core Image 进行渲染，得到对应的条码图像。</p>
<pre><code class="language-swift">// Create an image for a CIBarcodeDescriptor using CoreImage.framework
func imageFromBarcodeCodeDescriptor(_ descriptor: CIBarcodeDescriptor) -&gt; CIImage? 
{
    return CIFilter(name: &quot;CIBarcodeGenerator&quot;, 
                    withInputParameters: [&quot;inputBarcodeDescriptor&quot; : descriptor])
                      ?.outputImage 
}
</code></pre>
<blockquote>
<p>PS：</p>
<p>另外，CIBarcodeDescriptor 提供了许多有用的属性，比如 errorCorrectedPayload，maskPattern 等，便于获取条码的各种信息。</p>
</blockquote>
<p>通过这几个框架的无缝结合，可以做一些有趣的事情。</p>
<p>官方展示了这么一个 Demo，它可以从视频帧中，提取出条码，然后重新渲染到条码上，加上红色遮罩，突出效果。这里有两点很惊艳。</p>
<ul>
<li>识别到的条码已经重新渲染的位置都很准确。</li>
<li>注意看手指遮挡的部分，也能渲染出来。</li>
</ul>
<figure data-type="image" tabindex="19"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211102966.jpeg" alt="" loading="lazy"></figure>
<h3 id="using-core-image-with-vision">Using Core Image with Vision</h3>
<p>这个部分，有种捆绑销售的感觉～强行推一波新加入的 Vision。</p>
<p>我们知道 Core Image 可以对图像进行处理，比如裁剪，旋转，灰度等等。</p>
<p>而 Apple 新推出的 Vision 框架，在分析图像方面十分擅长，能提取出很多有用的信息。</p>
<p>所以它们配合在一起能做一些很棒的事情，比如这里介绍了一个，从一组图片中，生成一张不包含某个对象的图片。</p>
<blockquote>
<p>Photo from Video with Removal of Unwanted Objects</p>
</blockquote>
<p>具体如下图所示：</p>
<figure data-type="image" tabindex="20"><img src="https://cdn.jsdelivr.net/gh/colin1994/Images/202305211103073.png" alt="" loading="lazy"></figure>
<p>从五张同个场景的图片，通过 Vision 和 Core Image 结合，实现去除图片上移动的人物。</p>
<p>实现这个功能的具体步骤如下：</p>
<p>从视频中提取序列帧。这里简单的使用 AVFoundation 就能实现，我们可以得到几个对应的 CIImage。</p>
<p>图像对齐校正。提取出来的几张图片，可能因为拍摄设备的抖动，导致画面并不是完全一致，这时候就需要后期的调整。Vision 为我们提供了一个类 VNHomographicImageRegistrationRequest，专门用来做图像配准的。通过对比两张图片，能得到一个“对齐矩阵”，这样一张图片就能向另一张图片对齐。</p>
<blockquote>
<p>An image analysis request that determines the perspective warp matrix needed to align the content of two images.</p>
<p>Create and perform a homographic image registration request to align content in two images through a homography. A homography is an isomorphism of projected spaces, a bijection that maps lines to lines.</p>
</blockquote>
<p>具体代码如下：</p>
<pre><code class="language-swift">func homographicTransform(from image: CIImage, to reference: CIImage) -&gt; matrix_float3x3? {
  // Create the request and request handler
  let request = VNHomographicImageRegistrationRequest(targetedCIImage: image); 
  let requestHandler = VNImageRequestHandler(ciImage: reference, options: [:]);

  // Send the request to the handler
  try? requestHandler.perform([request]);

  // Get the observation
  guard let results = request.results,
        let observation = results.first as? VNImageHomographicAlignmentObservation
  else {
      return nil
  } 
  return observation.warpTransform
}
</code></pre>
<p>得到的矩阵，再传入 CIFilter 中，做对齐，对应的 kernel 脚本如下 ：</p>
<pre><code class="language-c++">// Core Image Metal kernel to apply a homography matrix
float2 warpHomography(float3x3 h, destination dest) 
{
  	float3 homogeneousDestCoord = float3(dest.coord(), 1.0);
  	float3 homogeneousSrcCoord = h * homogeneousDestCoord;
  	float2 srcCoord = homogeneousSrcCoord.xy / max(homogeneousSrcCoord.z, 0.000001);
  	return srcCoord; 
}
</code></pre>
<p>经过这个操作后，得到的 5 张图片，都是对齐过的，场景都是一致的。</p>
<p>但是画面上，人物的位置是不均匀分布的，所以要使用中位算法，取出最终的画面。</p>
<p>也就是每个像素点，都是5个图片一起分析，取出相同占比最高的那个像素值，结合成一个新的画面，就能剔除额外的人物。具体脚本如下：</p>
<pre><code class="language-swift">// Core Image Metal kernel to return the median of 5 images
inline void swap(thread float4 &amp;a, thread float4 &amp;b) 
{
	float4 tmp = a; a = min(a,b); b = max(tmp, b); // swap sort of two elements 
}

float4 medianReduction5(sample_t v0, sample_t v1, sample_t v2, sample_t v3, sample_t v4) 
{
	// using a Bose-Nelson sorting network
	swap(v0, v1); swap(v3, v4); swap(v2, v4); swap(v2, v3); swap(v0, v3); swap(v0, v2); 	swap(v1, v4); swap(v1, v3); swap(v1, v2); 
	return v2;
}
</code></pre>
<h2 id="延伸阅读">延伸阅读</h2>
<p><a href="https://developer.apple.com/videos/play/wwdc2017/510/">Advances in Core Image: Filters, Metal, Vision, and More</a></p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E6%A6%82%E8%BF%B0">概述</a></li>
<li><a href="#%E6%80%A7%E8%83%BD">性能</a>
<ul>
<li><a href="#metal">Metal</a>
<ul>
<li><a href="#write-cikernel-in-metal-shader-file">Write CIKernel in Metal shader file</a></li>
<li><a href="#compile-and-link-metal-shader-file">Compile and link Metal shader file</a></li>
<li><a href="#initialize-cikernel">Initialize CIKernel</a></li>
</ul>
</li>
<li><a href="#cirenderdestination">CIRenderDestination</a></li>
</ul>
</li>
<li><a href="#%E8%B0%83%E8%AF%95%E4%BF%A1%E6%81%AF">调试信息</a>
<ul>
<li><a href="#cirenderinfo">CIRenderInfo</a></li>
<li><a href="#quick-look">Quick Look</a></li>
</ul>
</li>
<li><a href="#%E6%96%B0%E5%8A%9F%E8%83%BD">新功能</a>
<ul>
<li><a href="#new-filter">New Filter</a></li>
<li><a href="#cibarcodedescriptor">CIBarcodeDescriptor</a></li>
<li><a href="#using-core-image-with-vision">Using Core Image with Vision</a></li>
</ul>
</li>
<li><a href="#%E5%BB%B6%E4%BC%B8%E9%98%85%E8%AF%BB">延伸阅读</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://colin1994.github.io/post/Core-Image-Custom-Filter/">
              <h3 class="post-title">
                Core Image 之自定义 Filter~
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  Powered by Gridea
  <a class="rss" href="https://colin1994.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
